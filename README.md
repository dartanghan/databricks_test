# --- Get your account_id
# https://accounts.azuredatabricks.net/user-management/users/6895889749198589?account_id=870b9035-b999-4ae5-9fba-c6c5e4b487d8
# databricks auth login --host https://accounts.azuredatabricks.net/ --account-id 870b9035-b999-4ae5-9fba-c6c5e4b487d8
ACCOUNT_ID=6895889749198589
ACCOUNT_UUID=870b9035-b999-4ae5-9fba-c6c5e4b487d8 ( used for some commands )
ACCOUNT_URL=https://accounts.azuredatabricks.net/ 

##
# There is a difference between workspace login and account login. We must use account login to connect using
# databrick cli. Otherwise we will not be able to get the users or accesses.
##

# in https://accounts.azuredatabricks.net/ create a service principal
# user management > Service principals > add service principal
# then add permission to the new principal in the desired workspace
# workspaces > [select the desired workspace] > Permissions > Add Permission


# --- Add a service principal
# https://accounts.azuredatabricks.net/user-management/serviceprincipals?account_id=870b9035-b999-4ae5-9fba-c6c5e4b487d8
# Use Microsoft Entra ID or Databricks Managed
Service Principal: githubaction 
ID: 147882943814739
UUID: b174f39f-1565-45df-847b-9229efcef16c
# Configure it as admin

# Create the service principal used by databricks
# Before execute this command, grab the user id using:
# databricks account service-principals list  
# In our case 147882943814739  b174f39f-1565-45df-847b-9229efcef16c  githubaction    ACTIVE
# ISSUER: URL OF GITHUB 
# AUDIENCES: optional
# SUBJECT: desired repo, may define a specific branch

databricks account service-principal-federation-policy create 147882943814739  --json '{
  "oidc_policy": {
    "issuer": "https://token.actions.githubusercontent.com",
    "audiences": [
        "https://github.com/dartanghan/databricks_test"
    ],
    "subject": "repo:dartanghan/databricks_test:environment:dev"
  }  
}'

### 
# When configuring github actions:
# DATABRICKS_AUTH_TYPE: github-oidc # hardcoded
# DATABRICKS_HOST: https://adb-2021064944982093.13.azuredatabricks.net/ # workspace URL
# DATABRICKS_CLIENT_ID: b174f39f-1565-45df-847b-9229efcef16c # service principal uuid
# 
# Useful commands
databricks account service-principal-federation-policy list 147882943814739
databricks auth login --host https://accounts.azuredatabricks.net/ --account-id 870b9035-b999-4ae5-9fba-c6c5e4b487d8
databricks account service-principals list  



# TL;DR
# - Create the service principal using account panel
# - Grant access to the workspace thru account panel
# - Add service-principal-federation-policy for it using command line
# - Give shared managed permission to the service principal inside workspace explorer tool in workspace



databricks account service-principal-federation-policy create 147882943814739  --json '{
  "oidc_policy": {
    "issuer": "https://token.actions.githubusercontent.com",
    "audiences": [
        "https://github.com/dartanghan/databricks_test"
    ],
    "subject": "repo:dartanghan/databricks_test:ref:refs/heads/main"
  }  
}'


# databricks_dp_01

The 'databricks_dp_01' project was generated by using the default-python template.

## Getting started

0. Install UV: https://docs.astral.sh/uv/getting-started/installation/

1. Install the Databricks CLI from https://docs.databricks.com/dev-tools/cli/databricks-cli.html

2. Authenticate to your Databricks workspace, if you have not done so already:
    ```
    $ databricks configure
    ```

3. To deploy a development copy of this project, type:
    ```
    $ databricks bundle deploy --target dev
    ```
    (Note that "dev" is the default target, so the `--target` parameter
    is optional here.)

    This deploys everything that's defined for this project.
    For example, the default template would deploy a job called
    `[dev yourname] databricks_dp_01_job` to your workspace.
    You can find that job by opening your workpace and clicking on **Workflows**.

4. Similarly, to deploy a production copy, type:
   ```
   $ databricks bundle deploy --target prod
   ```

   Note that the default job from the template has a schedule that runs every day
   (defined in resources/databricks_dp_01.job.yml). The schedule
   is paused when deploying in development mode (see
   https://docs.databricks.com/dev-tools/bundles/deployment-modes.html).

5. To run a job or pipeline, use the "run" command:
   ```
   $ databricks bundle run
   ```
6. Optionally, install the Databricks extension for Visual Studio code for local development from
   https://docs.databricks.com/dev-tools/vscode-ext.html. It can configure your
   virtual environment and setup Databricks Connect for running unit tests locally.
   When not using these tools, consult your development environment's documentation
   and/or the documentation for Databricks Connect for manually setting up your environment
   (https://docs.databricks.com/en/dev-tools/databricks-connect/python/index.html).

7. For documentation on the Databricks asset bundles format used
   for this project, and for CI/CD configuration, see
   https://docs.databricks.com/dev-tools/bundles/index.html.
